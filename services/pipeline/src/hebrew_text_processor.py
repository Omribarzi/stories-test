#!/usr/bin/env python3
"""
Hebrew Text Processor - ×˜×™×¤×•×œ ××ª×§×“× ×‘×˜×§×¡×˜ ×¢×‘×¨×™
××˜×¤×œ ×‘-RTL, × ×™×§×•×“, ×•×§×¨×™××•×ª ×œ×™×œ×“×™×
"""
from typing import List, Dict
import unicodedata
from arabic_reshaper import reshape
from bidi.algorithm import get_display
import requests
import time
import os
from anthropic import Anthropic


class HebrewTextProcessor:
    """
    ××¢×‘×“ ×˜×§×¡×˜ ×¢×‘×¨×™ ×œ×¡×¤×¨×™ ×™×œ×“×™×
    """

    def __init__(self):
        self.nikud_enabled = True

    def add_nikud(self, text: str, use_api: bool = True) -> str:
        """
        ××•×¡×™×£ × ×™×§×•×“ ×œ×˜×§×¡×˜ ×¢×‘×¨×™
        ××©×ª××© ×‘-Claude API ×œ× ×™×§×•×“ ××•×©×œ×

        Args:
            text: ×˜×§×¡×˜ ×¢×‘×¨×™
            use_api: ×”×× ×œ×”×©×ª××© ×‘-API (True) ××• ×¨×§ ×‘××™×œ×•×Ÿ ×™×“× ×™ (False)
        """
        if not self.nikud_enabled:
            return text

        # ×× ×”×˜×§×¡×˜ ×§×¦×¨ (×¢×“ 30 ××™×œ×™×), × ×¡×” Dicta API ×•××– Claude ×›×’×™×‘×•×™
        if use_api and len(text.split()) <= 30:
            # ×§×•×“× ×›×œ - × ×§×“ ××ª ×”××™×œ×™× ×©×§×™×™××•×ª ×‘××™×œ×•×Ÿ ×”×™×“× ×™
            # ×–×” ××•× ×¢ ×-Claude ×œ×§×‘×œ ××™×œ×™× ×‘×¢×™×™×ª×™×•×ª ×‘×›×œ×œ
            partial_result = self._manual_nikud(text)

            # ×‘×“×•×§ ×× ×™×© ××™×œ×™× ×©×¢×“×™×™×Ÿ ×¦×¨×™×›×•×ª × ×™×§×•×“
            nikud_chars = '\u05B0\u05B1\u05B2\u05B3\u05B4\u05B5\u05B6\u05B7\u05B8\u05B9\u05BB\u05BC\u05C1\u05C2'
            words = partial_result.split()
            words_without_nikud = [w for w in words if not any(c in nikud_chars for c in w.strip('.,;:!?"\''))]

            # ×× ×›×œ ×”××™×œ×™× ×›×‘×¨ ×× ×•×§×“×•×ª ××”××™×œ×•×Ÿ ×”×™×“× ×™ - ×¡×™×™×× ×•
            if not words_without_nikud:
                return partial_result

            # ×ª×Ÿ ×œ-Claude ××ª ×”×˜×§×¡×˜ ×”×—×œ×§×™ ×¢× ×‘×§×©×” ×œ×”×©×œ×™× ×¨×§ ××ª ×”×—×¡×¨
            try:
                result = self._add_nikud_claude(partial_result)
                return result
            except Exception as e:
                print(f"âš ï¸  ×©×’×™××” ×‘-Claude API: {e}")
                print(f"   ××©×ª××© ×‘××™×œ×•×Ÿ ×™×“× ×™")
                return partial_result
        else:
            # ×˜×§×¡×˜ ××¨×•×š ××• ××¦×‘ ×œ×œ× API - ×”×©×ª××© ×‘××™×œ×•×Ÿ ×™×“× ×™
            return self._manual_nikud(text)

    def _add_nikud_claude(self, text: str) -> str:
        """
        ××•×¡×™×£ × ×™×§×•×“ ×‘×××¦×¢×•×ª Claude API
        ××“×•×™×§ ×‘××™×•×—×“ ×œ×¢×‘×¨×™×ª ××•×“×¨× ×™×ª ×•×¡×¤×¨×™ ×™×œ×“×™×
        """
        try:
            client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

            prompt = f"""âš ï¸ CRITICAL BLOCKER RULE âš ï¸
You are ONLY adding nikud vowel marks to Hebrew text. You MUST NOT modify any Hebrew letters whatsoever.

IMPORTANT: The spelling you see is the AUTHOR'S INTENTIONAL CHOICE for a children's book. DO NOT "correct", "normalize", or "standardize" the spelling. Both ×›×ª×™×‘ ××œ× and ×›×ª×™×‘ ×—×¡×¨ are valid Hebrew, and the author has chosen ×›×ª×™×‘ ××œ× (full spelling with ×• and ×™ letters).

ğŸš« ABSOLUTELY FORBIDDEN - DO NOT DO THIS:
- Changing letters: ×§×•×¤×¡×” â†’ ×§×¤×¡×” (WRONG - removed ×•)
- Changing × ×™×’×© â†’ × ×’×© (WRONG - removed ×™)
- Changing ×’×™× ×” â†’ ×’× ×” (WRONG - removed ×™)
- "Correcting" from ×›×ª×™×‘ ××œ× (full spelling with ×•,×™) to ×›×ª×™×‘ ×—×¡×¨ (defective spelling)
- Removing ×• or ×™ letters under ANY circumstances
- "Fixing" or "normalizing" or "standardizing" spelling
- Any modification to base letters

âœ… ONLY ALLOWED ACTION:
- Add combining nikud marks (Unicode U+0591-U+05C7): Ö· Ö¸ Ö¶ Öµ Ö´ Ö¹ Ö» Ö° Ö¼ Ö¿ Ö½
- Preserve EVERY Hebrew letter EXACTLY as written by the author

EXAMPLES OF CORRECT BEHAVIOR:
Input:  ×§×•×¤×¡×” (with ×• - keep it!)
Output: ×§×•Ö¼×¤Ö°×¡Ö¸×” (kept ×•, only added Ö° Ö¸ Ö¼×•Ö¼ marks)

Input:  × ×•×¡×¤×ª (with ×• - keep it!)
Output: × ×•Ö¹×¡Ö¶×¤Ö¶×ª (kept ×•, only added marks)

Input:  ××¤×©×¨ (no ×• - don't add it!)
Output: ×Ö¶×¤Ö°×©Ö¸××¨ (no ×• added, only marks)

Input:  × ×™×’×© (with ×™ - keep it!)
Output: × Ö´×’Ö·Ö¼×©× (kept ×™, only added marks)

Input:  ×’×™× ×” (with ×™ - keep it!)
Output: ×’Ö´Ö¼× Ö¸Ö¼×” (kept ×™, only added marks)

Input:  ××•×¤× ×™×™× (with two ×™ - keep both!)
Output: ××•Ö¹×¤Ö·× Ö·Ö¼×™Ö´×™× (kept both ×™, only added marks)

THE TEXT TO VOCALIZE (DO NOT CHANGE ANY LETTERS):
{text}

VERIFICATION CHECKLIST BEFORE RESPONDING:
â–¡ Did I change the number of Hebrew letters? (If YES â†’ WRONG, start over)
â–¡ Did I remove any ×• or ×™? (If YES â†’ WRONG, start over)
â–¡ Did I "fix" ×›×ª×™×‘ ××œ× to ×›×ª×™×‘ ×—×¡×¨? (If YES â†’ WRONG, start over)
â–¡ Did I ONLY add nikud combining marks? (Must be YES)

MANDATORY RULES YOU MUST FOLLOW:
1. Add nikud to EVERY word â€” including proper names (××™×ª×™â†’×Ö´×™×ªÖ·×™, × ×•×¢×”â†’× ×•Ö¹×¢Ö¸×”, ×¨×•×¢×™â†’×¨×•Ö¹×¢Ö´×™, ××™×›×œâ†’×Ö´×™×›Ö·×œ)
2. NEVER skip words - children need complete nikud. Short words and names MUST get nikud too
3. Keep EXACT letter count - count Hebrew letters before and after, they must match EXACTLY
4. Preserve ALL ×• and ×™ letters exactly as they appear - the author chose this spelling intentionally
5. DO NOT apply any spelling "corrections" or "normalization" - just add nikud marks
6. If you're unsure whether to keep a letter - ALWAYS keep it, NEVER remove it

VERIFICATION BEFORE YOU RESPOND:
- Count Hebrew letters in input text: ____ letters
- Count Hebrew letters in your output (excluding nikud marks): ____ letters
- Do these numbers match? If NO, start over and fix it.

Return ONLY the vocalized text with nikud marks added, no explanations or comments."""

            response = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=1000,
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )

            nikud_text = response.content[0].text.strip()

            # ×•×•×“× ×©×–×” ×˜×§×¡×˜ ×¢×‘×¨×™ ×¢× × ×™×§×•×“
            if nikud_text and len(nikud_text) > 0:
                return nikud_text
            else:
                raise ValueError("Claude returned empty response")

        except Exception as e:
            print(f"âš ï¸  Claude API error: {e}")
            raise

    def _add_nikud_dicta(self, text: str) -> str:
        """
        ××•×¡×™×£ × ×™×§×•×“ ×‘×××¦×¢×•×ª Dicta API
        https://nakdan-5-3.loadbalancer.dicta.org.il
        """
        url = "https://nakdan-5-3.loadbalancer.dicta.org.il/addnikud"

        # ×¤×¦×œ ×œ×§×˜×¢×™× ×§×˜× ×™× (API ××•×’×‘×œ ×œ-~1000 ×ª×•×•×™×)
        max_chunk_size = 800
        if len(text) > max_chunk_size:
            # ×¤×¦×œ ×œ×¤×™ ××©×¤×˜×™×/×§×˜×¢×™×
            sentences = text.split('.')
            nikud_parts = []
            current_chunk = []
            current_len = 0

            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence:
                    continue

                if current_len + len(sentence) > max_chunk_size and current_chunk:
                    # ×©×œ×— ××ª ×”-chunk ×”× ×•×›×—×™
                    chunk_text = '. '.join(current_chunk) + '.'
                    nikud_parts.append(self._call_dicta_api(chunk_text))
                    current_chunk = [sentence]
                    current_len = len(sentence)
                else:
                    current_chunk.append(sentence)
                    current_len += len(sentence)

            # ×©×œ×— ××ª ×”-chunk ×”××—×¨×•×Ÿ
            if current_chunk:
                chunk_text = '. '.join(current_chunk) + '.'
                nikud_parts.append(self._call_dicta_api(chunk_text))

            return ' '.join(nikud_parts)
        else:
            return self._call_dicta_api(text)

    def _call_dicta_api(self, text: str) -> str:
        """
        ×§×¨×™××” ×œ-Dicta API - × × ×¡×” endpoint ×¤×©×•×˜ ×™×•×ª×¨
        """
        # Try the simpler endpoint first
        url = "https://nakdan-5-3.loadbalancer.dicta.org.il/nakdan/nikud"

        try:
            # Try simple text parameter
            response = requests.get(url, params={"text": text}, timeout=10)

            if response.status_code != 200:
                # Try POST with different format
                url2 = "https://nakdan-5-3.loadbalancer.dicta.org.il/addnikud"
                response = requests.post(
                    url2,
                    data=text.encode('utf-8'),
                    headers={"Content-Type": "text/plain; charset=utf-8"},
                    timeout=10
                )

            response.raise_for_status()

            # Try to parse response
            try:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    nikud_text = ''.join([item.get('w', '') for item in result])
                    return nikud_text
                elif isinstance(result, str):
                    return result
            except (json.JSONDecodeError, KeyError, TypeError, ValueError):
                # Maybe it's plain text response
                return response.text

        except Exception as e:
            # Silently fall back to manual nikud
            raise

    def _complete_missing_nikud(self, text: str) -> str:
        """
        ××©×œ×™× × ×™×§×•×“ ×—×¡×¨ - ×‘×•×“×§ ×›×œ ××™×œ×” ×•×× ×§×“ ××•×ª×” ××”××™×œ×•×Ÿ ×”×™×“× ×™ ×× ××™×Ÿ ×œ×” × ×™×§×•×“

        Args:
            text: ×˜×§×¡×˜ ×©×›×‘×¨ ×¢×‘×¨ × ×™×§×•×“ ×—×œ×§×™ (×-API)

        Returns:
            ×˜×§×¡×˜ ×¢× × ×™×§×•×“ ××œ× (API + ××™×œ×•×Ÿ ×™×“× ×™)
        """
        import re

        # ××™×œ×•×Ÿ × ×™×§×•×“ (× ×¢×ª×™×§ ×-_manual_nikud)
        nikud_dict = self._get_nikud_dictionary()

        # ×¤×¦×œ ×œ××™×œ×™× (×©××•×¨ ×¤×™×¡×•×§)
        words = text.split()
        completed_words = []

        nikud_chars = '\u05B0\u05B1\u05B2\u05B3\u05B4\u05B5\u05B6\u05B7\u05B8\u05B9\u05BB\u05BC\u05C1\u05C2'

        for word in words:
            # × ×§×” ×¡×™×× ×™ ×¤×™×¡×•×§
            clean_word = word.strip('.,;:!?"\'')
            prefix = word[:len(word) - len(word.lstrip('.,;:!?"\''))]
            suffix = word[len(clean_word) + len(prefix):]

            # ×”×¡×¨ × ×™×§×•×“ ×§×™×™× ×›×“×™ ×œ×‘×“×•×§ ×× ×”××™×œ×” ×‘××™×œ×•×Ÿ
            import unicodedata
            clean_word_no_nikud = ''.join(c for c in unicodedata.normalize('NFD', clean_word)
                                         if unicodedata.category(c) != 'Mn')

            # ×× ×”××™×œ×” ×§×™×™××ª ×‘××™×œ×•×Ÿ ×”×™×“× ×™ - ×”×©×ª××© ×‘×” (×¢×“×™×¤×•×ª ××•×—×œ×˜×ª ×¢×œ API)
            if clean_word_no_nikud in nikud_dict:
                completed_words.append(prefix + nikud_dict[clean_word_no_nikud] + suffix)
            else:
                # ××™×œ×” ×œ× ×‘××™×œ×•×Ÿ - ×”×©××¨ ×›××• ×©×”×™× (×¢× ××• ×‘×œ×™ × ×™×§×•×“ ××”-API)
                completed_words.append(word)

        return ' '.join(completed_words)

    def _get_nikud_dictionary(self) -> dict:
        """××—×–×™×¨ ××ª ×”××™×œ×•×Ÿ ×”×™×“× ×™ ×”××œ×"""
        return {
            # ××™×œ×™× ××¡×™×¤×•×¨ "× ×•×¢×” ×•×”×¤×™× ×” ×”×©×§×˜×”"
            "×™×•×©×‘×ª": "×™×•Ö¹×©Ö¶××‘Ö¶×ª",
            "×™×•×©×‘×™×": "×™×•Ö¹×©Ö°××‘Ö´×™×",
            "×™×•×©×‘": "×™×•Ö¹×©Öµ××‘",
            "×¢×œ": "×¢Ö·×œ",
            "×”×©×˜×™×—": "×”Ö·×©Ö¸Ö¼××˜Ö´×™×—Ö·",
            "××—×–×™×§×”": "×Ö·×—Ö²×–Ö´×™×§Ö¸×”",
            "××—×–×™×§": "×Ö·×—Ö²×–Ö´×™×§",
            "×”×ª×™× ×•×§": "×”Ö·×ªÖ´Ö¼×™× ×•Ö¹×§",
            "×ª×™× ×•×§": "×ªÖ´Ö¼×™× ×•Ö¹×§",
            "××“×‘×¨": "×Ö°×“Ö·×‘ÖµÖ¼×¨",
            "××œ": "×Ö¶×œ",
            "×‘×§×•×œ": "×‘Ö°Ö¼×§×•Ö¹×œ",
            "×¨×š": "×¨Ö·×šÖ°",
            "×§××”": "×§Ö¸×Ö¸×”",
            "×”×•×œ×›×ª": "×”×•Ö¹×œÖ¶×›Ö¶×ª",
            "×”×•×œ×š": "×”×•Ö¹×œÖµ×šÖ°",
            "×œ×—×“×¨": "×œÖ·×—Ö¶×“Ö¶×¨",
            "×—×“×¨": "×—Ö¶×“Ö¶×¨",
            "×‘×—×“×¨": "×‘Ö°Ö¼×—Ö¶×“Ö¶×¨",
            "×”×—×“×¨": "×”Ö·×—Ö¶×“Ö¶×¨",
            "×©×œ×”": "×©Ö¶××œÖ¸Ö¼×”Ö¼",
            "×©×œ×•": "×©Ö¶××œÖ¼×•Ö¹",
            "×¡×•×’×¨×ª": "×¡×•Ö¹×’Ö¶×¨Ö¶×ª",
            "××ª": "×Ö¶×ª",
            "×”×“×œ×ª": "×”Ö·×“Ö¶Ö¼×œÖ¶×ª",
            "×“×œ×ª": "×“Ö¶Ö¼×œÖ¶×ª",
            "×œ××˜": "×œÖ°×Ö·×˜",
            "×¢×•××“×ª": "×¢×•Ö¹×Ö¶×“Ö¶×ª",
            "×¢×•××“": "×¢×•Ö¹×Öµ×“",
            "×¢×•××“×™×": "×¢×•Ö¹×Ö°×“Ö´×™×",
            "×¢××“×”": "×¢Ö¸×Ö°×“Ö¸×”",
            "×¢××“": "×¢Ö¸×Ö·×“",
            "×œ×™×“": "×œÖ°×™Ö·×“",
            "×”××™×˜×”": "×”Ö·×Ö´Ö¼×˜Ö¸Ö¼×”",
            "××™×˜×”": "×Ö´×˜Ö¸Ö¼×”",
            "×‘××™×˜×”": "×‘Ö·Ö¼×Ö´Ö¼×˜Ö¸Ö¼×”",
            "×©×§×˜": "×©Ö¸××§Öµ×˜",
            "×©×§×˜×”": "×©Ö°××§Öµ×˜Ö¸×”",
            "×××•×“": "×Ö°×Ö¹×“",
            "×¨×§": "×¨Ö·×§",
            "×”× ×©×™××”": "×”Ö·× Ö°Ö¼×©Ö´××™×Ö¸×”",
            "× ×©×™××”": "× Ö°×©Ö´××™×Ö¸×”",
            "× ×•×©×": "× ×•Ö¹×©Öµ××",
            "× ×•×©××ª": "× ×•Ö¹×©Ö¶××Ö¶×ª",
            "× ×•×©××™×": "× ×•Ö¹×©Ö°××Ö´×™×",
            "×¨×•××”": "×¨×•Ö¹×Ö¸×”",
            "×”×‘×•×‘×”": "×”Ö·×‘Ö¼×•Ö¼×‘Ö¸Ö¼×”",
            "×‘×•×‘×”": "×‘Ö¼×•Ö¼×‘Ö¸Ö¼×”",
            "×”××“×£": "×”Ö·×Ö·Ö¼×“Ö¸Ö¼×£",
            "××“×£": "×Ö·×“Ö¸Ö¼×£",
            "×©×": "×©Ö¸××",
            "×œ×‘×“": "×œÖ°×‘Ö·×“",
            "××•×©×™×˜×”": "××•Ö¹×©Ö´××™×˜Ö¸×”",
            "×™×“": "×™Ö¸×“",
            "××•×¨×™×“×”": "××•Ö¹×¨Ö´×™×“Ö¸×”",
            "××—×‘×§×ª": "×Ö°×—Ö·×‘Ö¶Ö¼×§Ö¶×ª",
            "××•×ª×”": "××•Ö¹×ªÖ¸×”Ö¼",
            "××•×ª×•": "××•Ö¹×ª×•Ö¹",
            "×—×–×§": "×—Ö¸×–Ö¸×§",
            "×”×‘×˜×Ÿ": "×”Ö·×‘Ö¶Ö¼×˜Ö¶×Ÿ",
            "×‘×˜×Ÿ": "×‘Ö¶Ö¼×˜Ö¶×Ÿ",
            "×‘×‘×˜×Ÿ": "×‘Ö·Ö¼×‘Ö¶Ö¼×˜Ö¶×Ÿ",
            "×¨×•×¢×“×ª": "×¨×•Ö¹×¢Ö¶×“Ö¶×ª",
            "×§×¦×ª": "×§Ö°×¦Ö¸×ª",
            "×”×¨×¦×¤×”": "×”Ö¸×¨Ö´×¦Ö°×¤Ö¸Ö¼×”",
            "×¨×¦×¤×”": "×¨Ö´×¦Ö°×¤Ö¸Ö¼×”",
            "×¨×¦×¤×ª": "×¨Ö´×¦Ö°×¤Ö·Ö¼×ª",
            "××¡×“×¨×ª": "×Ö°×¡Ö·×“Ö¶Ö¼×¨Ö¶×ª",
            "×œ×‘×•×‘×”": "×œÖ·×‘Ö¼×•Ö¼×‘Ö¸Ö¼×”",
            "×©××™×›×”": "×©Ö°×‚×Ö´×™×›Ö¸×”",
            "×§×˜× ×”": "×§Ö°×˜Ö·× Ö¸Ö¼×”",
            "×§×˜×Ÿ": "×§Ö¸×˜Ö¸×Ÿ",
            "××œ×˜×¤×ª": "×Ö°×œÖ·×˜Ö¶Ö¼×¤Ö¶×ª",
            "×”×©×™×¢×¨": "×”Ö·×©ÖµÖ¼×‚×¢Ö¸×¨",
            "×©×™×¢×¨": "×©Öµ×‚×¢Ö¸×¨",
            "×©×™×¢×¨×•": "×©Ö°×‚×¢Ö¸×¨×•Ö¹",
            "×©×™×¢×¨×”": "×©Ö°×‚×¢Ö¸×¨Ö¸×”Ö¼",
            "× ×›× ×¡": "× Ö´×›Ö°× Ö¸×¡",
            "×‘×¤×ª×—": "×‘Ö·Ö¼×¤Ö¶Ö¼×ªÖ·×—",
            "×¤×ª×—": "×¤Ö¶Ö¼×ªÖ·×—",
            "×¤×•×ª×—": "×¤Ö¼×•Ö¹×ªÖµ×—Ö·",
            "××¡×ª×›×œ×ª": "×Ö´×¡Ö°×ªÖ·Ö¼×›Ö¶Ö¼×œÖ¶×ª",
            "××¡×ª×›×œ": "×Ö´×¡Ö°×ªÖ·Ö¼×›ÖµÖ¼×œ",
            "×•××¡×ª×›×œ": "×•Ö¼×Ö´×¡Ö°×ªÖ·Ö¼×›ÖµÖ¼×œ",
            "×¢×œ×™×•": "×¢Ö¸×œÖ¸×™×•",
            "×¢×œ×™×”": "×¢Ö¸×œÖ¶×™×”Ö¸",
            "××‘×": "×Ö·×‘Ö¸Ö¼×",
            "×•××‘×": "×•Ö°×Ö·×‘Ö¸Ö¼×",
            "×××": "×Ö´×Ö¸Ö¼×",
            "××•××¨": "××•Ö¹×Öµ×¨",
            "××•××¨×ª": "××•Ö¹×Ö¶×¨Ö¶×ª",
            "×××¨×”": "×Ö¸×Ö°×¨Ö¸×”",
            "×›×œ×•×": "×›Ö°Ö¼×œ×•Ö¼×",
            "××›×¡×”": "×Ö°×›Ö·×¡Ö¸Ö¼×”",
            "××‘×™×˜×”": "×Ö·×‘Ö´Ö¼×™×˜Ö¸×”",
            "××‘×™×˜": "×Ö·×‘Ö´Ö¼×™×˜",
            "×”×‘×™×˜×”": "×”Ö´×‘Ö´Ö¼×™×˜Ö¸×”",
            "×”×‘×™×˜×•": "×”Ö´×‘Ö´Ö¼×™×˜×•Ö¼",
            "××—×™×™×š": "×Ö°×—Ö·×™ÖµÖ¼×šÖ°",
            "×¢××•×§": "×¢Ö¸××•Ö¹×§",
            "×‘×™× ×”×": "×‘ÖµÖ¼×™× Öµ×™×”Ö¶×",
            "×¡×¤×¨": "×¡Öµ×¤Ö¶×¨",
            "×”×¡×¤×¨": "×”Ö·×¡ÖµÖ¼×¤Ö¶×¨",
            "×‘×¡×¤×¨": "×‘Ö·Ö¼×¡ÖµÖ¼×¤Ö¶×¨",
            "×—×•×–×¨×ª": "×—×•Ö¹×–Ö¶×¨Ö¶×ª",
            "×œ×¨×¦×¤×”": "×œÖ¸×¨Ö´×¦Ö°×¤Ö¸Ö¼×”",
            "×¤×•×ª×—×ª": "×¤Ö¼×•Ö¹×ªÖ·×—Ö·×ª",
            "××ª×§×¨×‘": "×Ö´×ªÖ°×§Ö¸×¨Öµ×‘",
            "××¦×‘×™×¢×”": "×Ö·×¦Ö°×‘Ö´Ö¼×™×¢Ö¸×”",
            "×ª××•× ×”": "×ªÖ°Ö¼××•Ö¼× Ö¸×”",
            "×‘×™×—×“": "×‘Ö°Ö¼×™Ö·×—Ö·×“",
            "×§×•×¨××™×": "×§×•Ö¹×¨Ö°×Ö´×™×",
            "×“×£": "×“Ö·Ö¼×£",
            "××—×“": "×Ö¶×—Ö¸×“",
            "×¢×›×©×™×•": "×¢Ö·×›Ö°×©Ö¸××™×•",
            "× ×©×¢× ×ª": "× Ö´×©Ö°××¢Ö¶× Ö¶×ª",
            "××”×××ª": "×Ö°×”Ö·×Ö°×”Ö¶×Ö¶×ª",
            "×¢×™× ×™×™×": "×¢Öµ×™× Ö·×™Ö´×",
            "×‘×¢×™× ×™×™×": "×‘Ö°Ö¼×¢Öµ×™× Ö·×™Ö´×",
            "×¡×•×’×¨×ª": "×¡×•Ö¹×’Ö¶×¨Ö¶×ª",
            "×× ×™×—": "×Öµ× Ö´×™×—Ö·",
            "×”×’×•×£": "×”Ö·×’Ö¼×•Ö¼×£",
            "×’×•×£": "×’Ö¼×•Ö¼×£",
            "×‘×©××™×›×”": "×‘Ö´Ö¼×©Ö°×‚×Ö´×™×›Ö¸×”",
            "× ×•×©××ª": "× ×•Ö¹×©Ö¶××Ö¶×ª",

            # ××™×œ×™× ×›×œ×œ×™×•×ª ×—×©×•×‘×•×ª
            "×”×œ×™×œ×”": "×”Ö·×œÖ·Ö¼×™Ö°×œÖ¸×”",
            "×œ×™×œ×”": "×œÖ·×™Ö°×œÖ¸×”",
            "×”×’×“×•×œ": "×”Ö·×’Ö¸Ö¼×“×•Ö¹×œ",
            "×’×“×•×œ": "×’Ö¸Ö¼×“×•Ö¹×œ",
            "×’×“×•×œ×”": "×’Ö°Ö¼×“×•Ö¹×œÖ¸×”",
            "×”×’×“×•×œ×•×ª": "×”Ö·×’Ö°Ö¼×“×•Ö¹×œ×•Ö¹×ª",
            "×©×œ": "×©Ö¶××œ",
            "××“×": "×Ö¸×“Ö¸×",
            "×‘××“×": "×‘Ö°Ö¼×Ö¸×“Ö¸×",
            "× ×•×¢×”": "× ×•Ö¹×¢Ö¸×”",
            "×¨×•×¢×™": "×¨×•Ö¹×¢Ö´×™",
            "×¡×™×¤×•×¨": "×¡Ö´×¤Ö¼×•Ö¼×¨",
            "××•×œ": "××•Ö¼×œ",
            "×”××¨××”": "×”Ö·×Ö·Ö¼×¨Ö°×Ö¸×”",
            "×”×××‘×˜×™×”": "×”Ö¸×Ö·×Ö°×‘Ö·Ö¼×˜Ö°×™Ö¸×”",
            "×”×—×•×": "×”Ö·×—×•Ö¼×",
            "×”×—×•××•×ª": "×”Ö·×—×•Ö¼××•Ö¹×ª",
            "×”×™×©×¨": "×”Ö·×™Ö¸Ö¼×©Ö¸××¨",
            "× ×¨××”": "× Ö´×¨Ö°×Ö¸×”",
            "× ×§×™": "× Ö¸×§Ö´×™",
            "×•××¡×•×“×¨": "×•Ö¼×Ö°×¡×•Ö¼×“Ö¸×¨",
            "××¡×•×“×¨": "×Ö°×¡×•Ö¼×“Ö¸×¨",
            "×”××ª×•×œ×ª×œ": "×”Ö·×Ö°×ª×•Ö¹×œÖ°×ªÖ¸Ö¼×œ",
            "×§×¤×¥": "×§Ö¸×¤Ö·×¥",
            "×œ×›×œ": "×œÖ°×›Ö¸×œ",
            "×”×›×™×•×•× ×™×": "×”Ö·×›Ö´Ö¼×•Ö¼×•Ö¼× Ö´×™×",
            "×”×™×": "×”Ö´×™×",
            "×”×•×": "×”×•Ö¼×",
            "×¤×™×’××ª": "×¤Ö´Ö¼×™×’Ö¸×³×Ö·×ª",
            "×”×›×•×›×‘×™×": "×”Ö·×›Ö¼×•Ö¹×›Ö¸×‘Ö´×™×",
            "×”×—×“×©×”": "×”Ö·×—Ö²×“Ö¸×©Ö¸××”",
            "×¨×¦×™× ×™": "×¨Ö°×¦Ö´×™× Ö´×™",
            "×× ×™": "×Ö²× Ö´×™",
            "×›×‘×¨": "×›Ö°Ö¼×‘Ö¸×¨",
            "×™×œ×“×”": "×™Ö·×œÖ°×“Ö¸Ö¼×”",
            "×™×œ×“": "×™Ö¶×œÖ¶×“",
            "×‘×œ×™": "×‘Ö°Ö¼×œÖ´×™",
            "×—×™×ª×•×œ×™×": "×—Ö´×™×ª×•Ö¼×œÖ´×™×",
            "×”×œ×‘": "×”Ö·×œÖµÖ¼×‘",
            "×œ×‘": "×œÖµ×‘",
            "×“×¤×§": "×“Ö¸Ö¼×¤Ö·×§",
            "×”××": "×”Ö·×Ö´×",
            "×‘×××ª": "×‘Ö¶Ö¼×Ö±×Ö¶×ª",
            "××•×›× ×”": "××•Ö¼×›Ö¸× Ö¸×”",
            "×’××”": "×’ÖµÖ¼×Ö¸×”",
            "×‘×š": "×‘Ö¸Ö¼×šÖ°",
            "××•×ª×§": "××•Ö¹×ªÖ¶×§",
            "×—×™×‘×§×”": "×—Ö´×‘Ö°Ö¼×§Ö¸×”",
            "×–×”": "×–Ö¶×”",
            "×–××ª": "×–Ö¹××ª",
            "×¦×¢×“": "×¦Ö·×¢Ö·×“",
            "×•×××™×¥": "×•Ö°×Ö·×Ö´Ö¼×™×¥",
            "×”×¨×™×": "×”Öµ×¨Ö´×™×",
            "××’×•×“×œ": "×Ö²×’×•Ö¼×“Ö¸×œ",
            "×œ××¢×œ×”": "×œÖ°×Ö·×¢Ö°×œÖ¸×”",
            "×•×—×™×™×š": "×•Ö°×—Ö´×™ÖµÖ¼×šÖ°",
            "×’×™×‘×•×¨×”": "×’Ö´Ö¼×‘Ö¼×•Ö¹×¨Ö¸×”",
            "×©×œ× ×•": "×©Ö¶××œÖ¸Ö¼× ×•Ö¼",
            "××‘×œ": "×Ö²×‘Ö¸×œ",
            "×”×¨×’×™×©×”": "×”Ö´×¨Ö°×’Ö´Ö¼×™×©Ö¸××”",
            "×”×¨×’×™×©": "×”Ö´×¨Ö°×’Ö´Ö¼×™×©×",
            "×¤×¨×¤×¨×™×": "×¤Ö·Ö¼×¨Ö°×¤Ö¸Ö¼×¨Ö´×™×",
            "××”": "×Ö¸×”",
            "××": "×Ö´×",
            "×œ×": "×œÖ¹×",
            "×ª×¦×œ×™×—": "×ªÖ·Ö¼×¦Ö°×œÖ´×™×—Ö·",
            "×™×¦×œ×™×—": "×™Ö·×¦Ö°×œÖ´×™×—Ö·",
            "×ª×ª×¢×•×¨×¨": "×ªÖ´Ö¼×ªÖ°×¢×•Ö¹×¨Öµ×¨",
            "×™×ª×¢×•×¨×¨": "×™Ö´×ªÖ°×¢×•Ö¹×¨Öµ×¨",
            "×¨×˜×•×‘×”": "×¨Ö°×˜×•Ö¼×‘Ö¸×”",
            "×¨×˜×•×‘": "×¨Ö¸×˜×•Ö¹×‘",
            "× ×©××”": "× Ö¸×©Ö°××Ö¸×”",
            "×™×›×•×œ×”": "×™Ö°×›×•Ö¹×œÖ¸×”",
            "××•×¨": "××•Ö¹×¨",
            "×¢××¨×™": "×¢Ö¸×Ö°×¨Ö´×™",
            "×‘×’××•×•×”": "×‘Ö°Ö¼×’Ö·×Ö²×•Ö¸×”",
            "××ª×”": "×Ö·×ªÖ¸Ö¼×”",
            "×‘×—×™×•×š": "×‘Ö°Ö¼×—Ö´×™Ö¼×•Ö¼×šÖ°",
            "×œ×—×©×”": "×œÖ¸×—Ö²×©Ö¸××”",
            "×œ×¢×¦××”": "×œÖ°×¢Ö·×¦Ö°×Ö¸×”Ö¼",
            "×©×›×‘×”": "×©Ö¸××›Ö°×‘Ö¸×”",
            "×•×”×‘×™×˜×”": "×•Ö°×”Ö´×‘Ö´Ö¼×™×˜Ö¸×”",
            "×‘×ª×§×¨×”": "×‘Ö·Ö¼×ªÖ´Ö¼×§Ö°×¨Ö¸×”",
            "×”×—×•×©×š": "×”Ö·×—Ö¹×©Ö¶××šÖ°",
            "×”×™×”": "×”Ö¸×™Ö¸×”",
            "×”×™×ª×”": "×”Ö¸×™Ö°×ªÖ¸×”",
            "××œ×": "×Ö¸×œÖµ×",
            "×‘×¦×œ×œ×™×": "×‘Ö´Ö¼×¦Ö°×œÖ¸×œÖ´×™×",
            "××•×–×¨×™×": "××•Ö¼×–Ö¸×¨Ö´×™×",
            "×˜×•×‘": "×˜×•Ö¹×‘",
            "××—×¨": "×Ö¸×—Ö¸×¨",
            "××—×›×”": "×Ö°×—Ö·×›Ö¶Ö¼×”",
            "×™×•×": "×™×•Ö¹×",
            "×—×“×©": "×—Ö¸×“Ö¸×©×",
            "×•×”×¤×™× ×”": "×•Ö°×”Ö·×¤Ö´Ö¼×™× Ö¸×”",
            "×¤×™× ×”": "×¤Ö´Ö¼×™× Ö¸×”",
            "×‘×¤×™× ×”": "×‘Ö°Ö¼×¤Ö´×™× Ö¸×”",
            "×”×©×§×˜×”": "×”Ö·×©Ö°Ö¼××§Öµ×˜Ö¸×”",
            "×”×¨×™×§": "×”Ö¸×¨Öµ×™×§",
            "×¨×™×§×™×": "×¨Öµ×™×§Ö´×™×",
            "×•×¨×™×§×™×": "×•Ö°×¨Öµ×™×§Ö´×™×",
            "×œ×‘× ×™×": "×œÖ°×‘Ö¸× Ö´×™×",
            "×”×§×™×¨×•×ª": "×”Ö·×§Ö´Ö¼×™×¨×•Ö¹×ª",
            "×”×§×™×¨": "×”Ö·×§Ö´Ö¼×™×¨",
            "×”×œ×‘×Ÿ": "×”Ö·×œÖ¸Ö¼×‘Ö¸×Ÿ",
            "×”×¤×•×¡×˜×¨×™×": "×”Ö·×¤Ö¼×•Ö¹×¡Ö°×˜Ö¶×¨Ö´×™×",
            "×§×•×¤×¡×”": "×§×•Ö¼×¤Ö°×¡Ö¸×”",
            "×¢×": "×¢Ö´×",
            "××›×•× ×™×•×ª": "×Ö°×›×•Ö¹× Ö´×™Ö¼×•Ö¹×ª",
            "×”×¦×¢×¦×•×¢": "×”Ö·×¦Ö·Ö¼×¢Ö²×¦×•Ö¼×¢Ö·",
            "×™×©": "×™Öµ×©×",

            # ××™×œ×™× ×©Claude ××©× ×” ×‘××•×¤×Ÿ ×©×’×•×™ (××¡×™×¨ ×™ ××• ×•) - ×›×ª×™×‘ ××œ×
            "× ×™×’×©": "× Ö´×™×’Ö·Ö¼×©×",  # ×©×•××¨ ×™
            "×’×™× ×”": "×’Ö´Ö¼×™× Ö¸Ö¼×”",  # ×©×•××¨ ×™
            "××•×¤× ×™×™×": "××•Ö¹×¤Ö·× Ö·Ö¼×™Ö´×™×",
            "×—×œ×•×Ÿ": "×—Ö·×œÖ¼×•Ö¹×Ÿ",
            "×œ×—×œ×•×Ÿ": "×œÖ·×—Ö·×œÖ¼×•Ö¹×Ÿ",
            "×‘×—×•×¥": "×‘Ö·Ö¼×—×•Ö¼×¥",
            "×¨×•×›×‘": "×¨×•Ö¹×›Öµ×‘",
            "×‘××¢×’×œ×™×": "×‘Ö°Ö¼×Ö·×¢Ö°×’Ö¸Ö¼×œÖ´×™×",
            "×–×•×›×¨": "×–×•Ö¹×›Öµ×¨",
            "×”×§×˜× ×”": "×”Ö·×§Ö°Ö¼×˜Ö·× Ö¸Ö¼×”"
        }

    def _manual_nikud(self, text: str) -> str:
        """
        × ×™×§×•×“ ×™×“× ×™ ×œ××™×œ×™× × ×¤×•×¦×•×ª ×‘×¡×¤×¨×™ ×™×œ×“×™×
        """
        # ×”×©×ª××© ×‘××™×œ×•×Ÿ ×”××¨×›×–×™
        nikud_dict = self._get_nikud_dictionary()

        # ×”×—×œ×¤×ª ××™×œ×™× ×¢× × ×™×§×•×“
        words = text.split()
        nikud_words = []
        for word in words:
            # × ×§×” ×¡×™×× ×™ ×¤×™×¡×•×§
            clean_word = word.strip('.,;:!?"\'')
            prefix = word[:len(word) - len(word.lstrip('.,;:!?"\''))]
            suffix = word[len(clean_word) + len(prefix):]

            # ×—×¤×© ×‘××™×œ×•×Ÿ
            if clean_word in nikud_dict:
                nikud_words.append(prefix + nikud_dict[clean_word] + suffix)
            else:
                nikud_words.append(word)

        return ' '.join(nikud_words)

    def process_for_pdf(self, text: str, add_nikud: bool = True, apply_bidi: bool = True) -> str:
        """
        ××¢×‘×“ ×˜×§×¡×˜ ×‘×•×“×“ ×œ×ª×¦×•×’×” ×‘-PDF
        ××—×™×œ × ×™×§×•×“ ×•-RTL transformation

        Args:
            text: ×˜×§×¡×˜ ×¢×‘×¨×™
            add_nikud: ×”×× ×œ×”×•×¡×™×£ × ×™×§×•×“
            apply_bidi: ×”×× ×œ×”×—×™×œ bidi transformation (×›×‘×” ×œ×¤×•× ×˜×™× ×©××˜×¤×œ×™× ×‘-RTL ×‘×¢×¦××)

        Returns:
            ×˜×§×¡×˜ ××¢×•×‘×“ ××•×›×Ÿ ×œ×ª×¦×•×’×”
        """
        # ×©×œ×‘ 1: ×”×•×¡×£ × ×™×§×•×“
        if add_nikud:
            text = self.add_nikud(text)

        # ×©×œ×‘ 2: RTL transformation (×¨×§ ×× × ×“×¨×©)
        if apply_bidi:
            if add_nikud:
                # ×¢×‘×•×¨ ×˜×§×¡×˜ ×¢× × ×™×§×•×“ - ××œ ×ª×©×ª××© ×‘-reshape (×”×•× ×œ×¢×¨×‘×™×ª)
                # Normalize ×§×•×“× ×¢× NFD (Decomposition) ×›×“×™ ×œ×”×¤×¨×™×“ ××ª ×”× ×™×§×•×“ ××”××•×ª
                text = unicodedata.normalize('NFD', text)
                # ×¢×›×©×™×• ×¢×©×” bidi transformation
                bidi_text = get_display(text)
                # Normalize ×‘×—×–×¨×” ×œ-NFC (Composition) ×›×“×™ ×œ×”×“×‘×™×§ ××ª ×”× ×™×§×•×“ ×œ××•×ª
                bidi_text = unicodedata.normalize('NFC', bidi_text)
            else:
                # ×˜×§×¡×˜ ×‘×œ×™ × ×™×§×•×“ - reshape + bidi
                reshaped = reshape(text)
                bidi_text = get_display(reshaped)
            return bidi_text
        else:
            # ×¤×•× ×˜×™× ×›××• FrankRuehl ××˜×¤×œ×™× ×‘-RTL ×‘×¢×¦××
            return text

    def split_to_lines(self, text: str, max_width: int,
                       font_name: str, font_size: int,
                       canvas_obj) -> List[str]:
        """
        ××—×œ×§ ×˜×§×¡×˜ ×¢×‘×¨×™ ×œ×©×•×¨×•×ª ×‘×¦×•×¨×” × ×›×•× ×”

        CRITICAL: ××¤×¦×œ ×œ×¤× ×™ bidi transformation!

        Args:
            text: ×˜×§×¡×˜ ×¢×‘×¨×™ (×œ×¤× ×™ ×¢×™×‘×•×“)
            max_width: ×¨×•×—×‘ ××§×¡×™××œ×™ ×‘×¤×™×§×¡×œ×™×
            font_name: ×©× ×”×¤×•× ×˜
            font_size: ×’×•×“×œ ×”×¤×•× ×˜
            canvas_obj: ××•×‘×™×™×§×˜ Canvas ×©×œ reportlab

        Returns:
            ×¨×©×™××ª ×©×•×¨×•×ª ××¢×•×‘×“×•×ª ××•×›× ×•×ª ×œ×ª×¦×•×’×”
        """
        # ×©×œ×‘ 1: ×”×•×¡×£ × ×™×§×•×“ (×œ×¤× ×™ ×¤×™×¦×•×œ!)
        text_with_nikud = self.add_nikud(text)

        # ×©×œ×‘ 2: ×¤×¦×œ ×œ××™×œ×™× (×œ×¤× ×™ bidi!)
        words = text_with_nikud.split()

        # ×©×œ×‘ 3: ×‘× ×” ×©×•×¨×•×ª ×œ×¤×™ ×¨×•×—×‘
        lines_raw = []
        current_line = []

        for word in words:
            # ×‘×“×•×§ ×¨×•×—×‘ ×¢× ×”××™×œ×” ×”× ×•×›×—×™×ª
            test_line = ' '.join(current_line + [word])

            # ×”×—×œ bidi ×–×× ×™×ª ×œ×‘×“×™×§×”
            test_line_display = self.process_for_pdf(test_line, add_nikud=False)
            line_width = canvas_obj.stringWidth(test_line_display, font_name, font_size)

            if line_width <= max_width:
                current_line.append(word)
            else:
                if current_line:
                    lines_raw.append(' '.join(current_line))
                current_line = [word]

        if current_line:
            lines_raw.append(' '.join(current_line))

        # ×©×œ×‘ 4: ×”×—×œ bidi ×¢×œ ×›×œ ×©×•×¨×” ×‘× ×¤×¨×“
        lines_processed = []
        for line in lines_raw:
            processed = self.process_for_pdf(line, add_nikud=False)  # ×›×‘×¨ ×™×© × ×™×§×•×“
            lines_processed.append(processed)

        return lines_processed

    def get_display_text(self, text: str, add_nikud: bool = True) -> str:
        """
        Alias for process_for_pdf - ×œ×ª××™××•×ª ××—×•×¨×”
        """
        return self.process_for_pdf(text, add_nikud=add_nikud)


# Demo
if __name__ == "__main__":
    processor = HebrewTextProcessor()

    test_text = "× ×•×¢×” ×¢××“×” ××•×œ ×”××¨××” ×‘×—×“×¨ ×”×××‘×˜×™×”"

    print("Original:")
    print(test_text)

    print("\nWith nikud:")
    with_nikud = processor.add_nikud(test_text)
    print(with_nikud)

    print("\nProcessed for PDF:")
    processed = processor.process_for_pdf(test_text)
    print(processed)
